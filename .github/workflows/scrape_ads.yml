name: Scrape Search Ads

on:
  workflow_dispatch: # Allows manual triggering
  push:
    paths:
      - 'scrape_ads.py' # This specifies that the workflow runs ONLY when scrape_ads.py is changed
      - 'requirements.txt' # It's good practice to also include requirements.txt if changes there impact the script
  schedule:
    - cron: '0 0 * * *' # Runs daily at midnight UTC

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9' # Or your preferred Python version

    - name: Install dependencies
      run: pip install -r requirements.txt # Install playwright library first

    - name: Install Playwright browsers # Corrected command here
      run: python -m playwright install --with-deps chromium

    - name: Run ad scraper
      env:
        KEYWORDS_JSON: '["elekter", "elektrileping", "elektripaketid", "elektribörs", "börsielekter", "elektri börsihind", "elektri paketid", "elektrimüüjad"]'
        OUTPUT_FILE: competitor_ads.json
        HEADLESS: true
        MAX_ADS_PER_PAGE: 5
        DELAY_BETWEEN_SEARCHES_SECONDS: 10
        PROXY_SERVER: ${{ secrets.PROXY_SERVER }}
        PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }}
        PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}
      run: python scrape_ads.py

    - name: Commit results
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "Automated ad scraping results"
        file_pattern: competitor_ads.json
        branch: main
