name: Scrape Search Ads

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    - cron: '0 0 * * *' # Runs daily at midnight UTC (adjust as needed for EEST)

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9' # Or your preferred Python version

    - name: Install Playwright browsers
      run: playwright install --with-deps chromium

    - name: Install dependencies
      run: pip install -r requirements.txt # Now just 'requirements.txt'

    - name: Run ad scraper
      env:
        KEYWORDS_JSON: ${{ secrets.KEYWORDS_JSON }}
        OUTPUT_FILE: ${{ secrets.OUTPUT_FILE }}
        HEADLESS: ${{ secrets.HEADLESS }}
        MAX_ADS_PER_PAGE: ${{ secrets.MAX_ADS_PER_PAGE }}
        DELAY_BETWEEN_SEARCHES_SECONDS: ${{ secrets.DELAY_BETWEEN_SEARCHES_SECONDS }}
        PROXY_SERVER: ${{ secrets.PROXY_SERVER }}
        PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }}
        PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}
      run: python scrape_ads.py # Now just 'scrape_ads.py'

    - name: Commit results
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "Automated ad scraping results"
        file_pattern: competitor_ads.json # This file will be in the root
        branch: main # Or your desired branch
