name: Scrape Search Ads

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    - cron: '0 0 * * *' # Runs daily at midnight UTC (adjust as needed for EEST)

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9' # Or your preferred Python version

    - name: Install Playwright browsers
      run: playwright install --with-deps chromium

    - name: Install dependencies
      run: pip install -r requirements.txt

    - name: Run ad scraper
      env:
        # IMPORTANT: These keywords are for the GitHub Actions environment.
        # Make sure this JSON string is correctly formatted.
        KEYWORDS_JSON: '["elekter", "elektrileping", "elektripaketid", "elektribörs", "börsielekter", "elektri börsihind", "elektri paketid", "elektrimüüjad"]'
        OUTPUT_FILE: competitor_ads.json
        HEADLESS: true
        MAX_ADS_PER_PAGE: 5
        DELAY_BETWEEN_SEARCHES_SECONDS: 10
        PROXY_SERVER: ${{ secrets.PROXY_SERVER }} # Your proxy server address (e.g., http://your_proxy_ip:port)
        PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }} # Your proxy username (if applicable)
        PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }} # Your proxy password (if applicable)
      run: python scrape_ads.py

    - name: Commit results
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "Automated ad scraping results"
        file_pattern: competitor_ads.json # This file will be in the root
        branch: main # Or your desired branch
